# sbt in Action

## Chapter 1. Why sbt?

### Why a Build Tool?

### Why sbt?

So two things that we like to have in our builds are flexibility and the ability to insert custom tasks easily.

#### How sbt works

Let's take a quick look at how sbt works.
sbt consists of two things: tasks and settings.

##### sbt tasks

sbt is built around tasks.
Unlike Maven, there are no phases, goals, or executions, just tasks.
You want to do something, you execute a task.
You want to ensure that a task runs after another task, you add an explicit dependency between the tasks.
If you want to use the results of a task in another task, you push the output from one task into another.
The results of one task are automatically available in dependent tasks.
The output of an sbt task is a value (which can be of any type), so this can be passed around with ease.
Multiple tasks can depend on the output of the same task.
By default, sbt runs all of the tasks in parallel, but by using the dependency tree, it can work out what should be sequential and what can be parallel.

sbt puts in place a default structure and layout.
Out of the box you get your `compile` task, `test` task, and `publish` task, and these work as expected: if you run the `test` task, sbt will run the `compile` task beforehand.
The `compile` task compiles Scala and Java by default.
The layout is similar to that of a standard Maven project.

A task in sbt is Scala code.
There isn't any intermediate XML;
You write the code directly in your build configuration.
This gives you all of the power of Scala in your build and avoids lots of portability problems.

##### sbt settings

A setting in sbt is just a value.
This could be the name of the project or the version of Scala to use.

#### Plugin architecture vs. tasks

##### How to define an sbt task

In sbt, it's easy to add a custom task to a build, and if you use it in more than one place, it's relatively easy to add a plugin that can be used from more than one place.
Configuration and tasks are defined using a combination of declaration and standard Scala code.

Note that this code appears directly in the build definition file, so as soon as it's checked into the version control system, it's available to the other users of the project, including your continuous integration system.

Once your task is generic enough or useful enough, you can turn the task definition via a repository.

#### Phases vs. task dependencies

With sbt, you have to specify an explicit dependency between tasks.
This enables sbt to run tasks *in parallel by default*.

#### Passing information around your build

In sbt, you can simply return the information from the first task as the return value of the task.

This is another area where sbt comes into its own.
You know that the task has executed because you have the value.

### Working with Scala

A Scala build tool requires the same things as a Java build tool, but there are a couple of additional problems that come with Scala builds.

#### Cross-compilation for multiple Scala versions

The most prominent example is cross-compilation.
First, a bit of background: Scala (the library) is binary-compatible between minor version releases.

sbt has built-in options for this sort of thing.
You can tell sbt to cross-compile directly in the build definition.

#### Lots more classes in Scala

The Scala compiler tends to generate more classes (.class files) than would be generated by the equivalent program written in Java.
This is due to how Scala generates code for closures and other constructs that aren't supported directly in the JVM, which it must simulate.
The concrete effect is that the JVM takes longer to get up and running with Scala code - and not only on compilation but on test startup as well.

#### Slow Scala compilation

One of the frustrations of Scala is the compilation speed, which is seen by some (most?) developers as slow, at least compared to Java.
sbt has good incremental compilation;
it recompiles only those files that have changed.

### Multiproject builds

sbt is also designed specifically for multiproject (sometimes called multimodule) builds.

### Dependency resolution

sbt uses Ivy for its dependency resolution.

## Chapter 2. Getting started

The simple build tool (sbt) is used for building Java and Scala projects;
its purpose is to allow users to skillfully perform the basics of building and to customize endlessly.
sbt, at its core, provides a parallel execution engine and configuration system that allow you to design an efficient and robust script to build your software.

### Setting up sbt

Everything needed to run sbt is in the sbt/bin directory.
This directory consists of the actual sbt launcher and convenience scripts that provide easier configuration of the Java runtime.
The sbt/bin directory must be placed in the `PATH` to use sbt via the command line.

#### Running sbt

This is sbt downloading the actual pieces needed to run the build.
By default, sbt includes only the bare minimum it needs to launch builds.
The first time you run a project, sbt needs to download the remaining portions required, as well as compile the local project's build definition.
This process happens only the first time a dependency is needed or when your build changes.

### Setting up a build

Every project using sbt should have two files:
* project/build.properties
* build.sbt

The *build.properties* file is used to inform sbt which version it should use for your build, and the *build.sbt* file defines the actual settings for your build.

#### Tasks

Tasks are things that sbt build can do for you, like compiling a project, creating documentation, or running tests.

#### Settings

Run the `settings` help on the sbt command line and see if that points you to to where source code for the project should go
```
> settings

This is a list of settings defined for the current project.
It does not list the scopes the settings are defined in; use the 'inspect' command for that.

  baseDirectory                  The base directory.  Depending on the scope, this is the base directory for the build, project, configuration, or task.
  classDirectory                 Directory for compiled classes and copied resources.
  javaSource                     Default Java source directory.
  libraryDependencies            Declares managed dependencies.
  managedResourceDirectories     List of managed resource directories.
  name                           Project name.
  organization                   Organization/group ID.
  publishArtifact                Enables (true) or disables (false) publishing an artifact.
  resourceDirectory              Default unmanaged resource directory, used for user-defined resources.
  scalaSource                    Default Scala source directory.
  scalaVersion                   The version of Scala used for building.
  sourceDirectories              List of all source directories, both managed and unmanaged.
  sourceDirectory                Default directory containing sources.
  target                         Main directory for files generated by the build.
  unmanagedBase                  The default directory for manually managed libraries.
  unmanagedResourceDirectories   Unmanaged resource directories, containing resources manually created by the user.
  unmanagedSourceDirectories     Unmanaged source directories, which contain manually created sources.

More settings may be viewed by increasing verbosity.  See 'help settings'
```
Again, there are a lot of default settings.
We'll make another note to return here when needed and focus on the goal of adding some source code.
Because we're into the Scala language, let's look more at the following `scalaSource` setting (for those interested in Java, the `javaSource` setting provides the same function as `scalaSource`):
```
> scalaSource
[info] progfun / Compile / scalaSource
[info] 	/Users/jwang/scala-notes/progfun/src/main/scala
[info] Compile / scalaSource
[info] 	/Users/jwang/scala-notes/src/main/scala
```

### Running code

In sbt, running code can take on a few different flavors.

#### Interacting with code in the interpreter

One of the greatest advantages offered in sbt is the ability to explore a project through the Scala REPL (a.k.a Scala console or Scala interpreter).
This provides a command-line interface where you can directly construct classes, call methods, and see what happens.

### Testing code

> Make sure to reload
>
> Any change to the *build.sbt* file or files in the *project/* directory won't be immediately available within the sbt console.
> The `reload` command tells sbt to re-examine the project definition and rewire the project.
> When you edit an sbt build, you'll need to reload.

#### Running tasks when sources change

One of sbt's most powerful features is the ability to rerun a task when it detects that a source file has changed.

#### Selecting tests with interactive tasks

Another core feature of sbt is the ability to interact with the build via command-line autocomplete options on tasks.
```sbt
> help testOnly
```

## Chapter 3. Core concepts

### Creating builds

Let's look at the `build.properties` file you defined:
```sbt
sbt.version = 1.3.13
```
Although this file can be used to specify several things, it's commonly used only to specify the sbt version.

The core of the build is its `build.sbt` file.

Every sbt build is created by defining a group of settings, projects, and definitions.

### Defining settings

Settings are the bread and butter of sbt builds.
They're the mechanism by which you configure sbt to perform the work you need for your build.
sbt reads all the settings defined in your build at load time and runs their initializations, which produce the final setting values used for your build.

A setting consists of three parts: a key, an initialization, and an operator that associates the key and initialization.
A setting is used to change an aspect of the build or add functionality.

>Typesafe settings
>
>In sbt, every key has one and only one type.
>Any value placed into a setting must match the exact type.
>This prevents mismatched data from being passed around the build.

>Defining dependencies
>
>sbt provides a convenient syntax for defining dependencies on remote artifacts using the `%` method.
>This method is used to create `ModuleID` instances.
>To define a `ModuleID` in sbt, write `"groupId" % "artifactId" % "version"` and it will automatically become an instance of a `ModuleID`.

The `libraryDependencies` key holds a value of type `Seq[ModuleID]`.
The `+=` operator is used to take the previous value assigned to the `libraryDependencies` setting and append the new `ModuleID` value to it.

There are two operators to append values to existing settings that contain a sequence of items: `+=` and `++=`.
The `++=` operator works similarly to the `+=` operator, but instead of adding a single value, it adds multiple values given as a sequence.

#### Initializations

In sbt, an initialization is a Scala expression that can produce a value, and it may use other settings to do so.

An *initialization* is an expression that produces a value and may use other settings to do so.
You can access the value of another setting using the `value` method.

>Initializations are code
>
>Initializations are Scala code.
>You can read environment variables, properties, files, or anything else available in the JVM.
>sbt attempts to run all the initializations for a build when it starts.
>Any failures in an initialization will cause the build to fail to load, so make sure to catch exceptions as needed when defining initializations for settings!

Initializations can be created from more than one setting.

>Circular references
>
>Because sbt can use values of one setting to instantiate another, it's possible to create circular references.

To recap, in sbt there are three operators used to create settings:

| Operator | Usage |
| --- | --- |
| `:=` | Assigns an initialization expressions to a key. Overrides any previous value. |
| `+=` | Appends an initialization expression to the existing sequence in a key. |
| `++=` | Appends an initialization of a sequence of values to the existing sequence in a key. |

>One operator to rule them all
>In sbt all settings can be implemented in terms of the `:=` operator.

### Creating and executing tasks

Builds are about accomplishing tasks, from running a compiler to generating zip files for distribution.
Tasks are the means to repeatedly perform some operation, like compiling your project, generating documentation, or running tests.
In sbt a task is like a setting that runs every time you request its value.
That is, every time you make a request to sbt's task engine, each task required will be run once for that request.
```sbt
val gitHeadCommitSha = taskKey[String] (
  "Determines the current git commit SHA"
)
```
This is a *definition* in sbt.
A definition defines a variable or method for reuse within sbt settings.
In sbt, definitions are compiled first and can reference previous definitions.
That's why definitions are defined using the `=` operator and not the `:=` operator.
A definition isn't assigning a value into a setting but is defining some Scala code to help define the build.

Because settings are executed after definitions, settings can refer to any definition in the build file.

```sbt
gitHeadCommitSha := Process("git rev-parse HEAD").lineStream.head
```
The way to think of this process is that the definition (`=`) is constructing a new slot where computed build values can go.
The setting (`:=`) is constructing a function that will compute the value for the slot when needed.

#### Task dependencies

Just as settings may depend on other settings, tasks may also depend on settings as well as the output from other tasks.
When the user requests a task to be executed, sbt will run all of the dependent tasks (once) and pass their values to the requested task.

### Using configurations

Configurations are namespaces for keys.
They allow the same key to be reused to serve different purposes.
sbt comes with several configurations in the default build

These configurations are used to split settings and tasks across higher-level goals.
For example, the task defined at `sources in Compile` collects the source files that will be compiled for your production artifacts, whereas `sources in Test` defines the source files that will be compiled to run your unit tests.

Configurations provide consistencies between tasks within sbt.
A given flow of tasks can be repeated across two different configurations.
Also, tasks in one configuration can depend on tasks in another configuration.
Because sbt runs all tasks in parallel by default, configurations can be used to create mirror tasks that can run in parallel.

Configurations provide one means to namespace settings and tasks, but there's another mechanism you can use: defining with subprojects.

### Defining with subprojects

After creating the new subproject, restart sbt and try to interact with it.
First run the `reload` command in the sbt prompt so your new `build.sbt` definition is compiled and loaded:
```
> reload
```
Next run the `projects` command to see if your new subproject shows up:
```
> projects
```

>Projects need their own directories
>
>In sbt, the default project settings assume that each project has its own base directory.
>Each project in your build should have its own base directory that's different from any other project.
>Within this base directory, you'll find the directories for source code, testing code, and so on.

The root directory is the default target for settings found in the `build.sbt` file.
This means that all the configuration you have so far for testing applies only to code in the root project.

Project dependencies are defined using the `dependsOn` method of `Project`.

>Project definition order matters!
>
>Just like any other Scala object, any values defined can't be referenced before they're declared.
>Because of this, it drastically simplifies life to declare projects using `lazy val`s.
>It's such a common issue with circular references that we recommend always using `lazy val`s to define projects.
>In sbt, across all projects, tasks are structured as a dependency graph.
>sbt will ensure that tasks from one project are executed before they're used by another project.

### Putting it all together

sbt is built on top of Scala, an expressive language with a lot of nice features.
You can start using these to reduce clutter in your build and ensure that it's easy to maintain.
You'll start by reducing some of the clutter in creating your projects.

Now that the task is attached to the build itself, you only have to define it once, but all projects can make use of its results.
This is great for files/settings that are truly shared across all projects, because it means sbt will execute the task only once for all projects that request the value.
Also it means that you don't have to redefine the setting in every project that needs it.
By default, if sbt doesn't find a task/setting for a key in a given project, it will fall back to task/settings defined in the build itself.

## Chapter 4. The default build

### Compiling your code

One of the primary purposes of a build tool is to compile code.
But in order to compile code, sbt first needs to know a few things.
You can ask sbt what it needs using the `inspect tree` command on the sbt prompt.

The command's output is an ASCII tree detailing which tasks/settings the compile task depends on and what values those settings/tasks return.
This command is available against any sbt task/setting, and it's an amazing resource when learning how a new project works.

As shown in this more easily readable tree, compilation requires three things:
* A sequence (list) of source files
* A sequence (list) of libraries
* A sequence (list) of compiler configuration options

### Finding your sources

As it does for many other aspects of a build, sbt applies certain conventions when looking for your source code.
But you can easily customize the way sources are organized, if necessary.

>Convention over configuration
>
>It has become a widely adopted paradigm in software engineering to make it as easy as possible for the users to get simple things done by minimizing the number of explicit decisions necessary through conventions.
>On the other hand, it should still be possible to get complex things done by defining nonstandard aspects through configuration.

#### Standard organization of sources

Let's take a look at the `sources` task and determine the source layout conventions from there.
A simple run of `inspect tree sources` reveals the structure

You can see that the list of sources is taken from two aggregates:
* **unmanagedSources** - A discovered list of source files using standard project conventions
* **managedSources** - A list of sources that are either generated from the build or manually added

For sbt, the unmanaged sources are discovered *by convention*.
Unmanaged means you (not sbt) have to do the work of adding, modifying, and tracking the source files, whereas managed source files are ones that sbt will create and track for you.

Unmanaged sources make use of a set of file filters and a default set of directories to produce the sequence of source files for the project.
As shown in the dependency tree, the directories defined by the `javaSource` and `scalaSource` settings make up the set of directories where sbt looks for sources.
Let's see what these settings are by default (the convention):
```
> show javaSource
[info] progfun / Compile / javaSource
[info] 	/Users/jwang/scala-notes/progfun/src/main/java
[info] Compile / javaSource
[info] 	/Users/jwang/scala-notes/src/main/java

> show scalaSource
[info] progfun / Compile / scalaSource
[info] 	/Users/jwang/scala-notes/progfun/src/main/scala
[info] Compile / scalaSource
[info] 	/Users/jwang/scala-notes/src/main/scala
```
By default, the set of sources that sbt uses for a project comes from the src/main/java directory and the src/main/scala directory.
These directories are scanned for files, and those files that pass the default filters are used in compilation.

Similar to how sbt has a `sources` task to collect sources, there's a corresponding `resources` task, which collects all the files that should be available at runtime.

Those familiar with Maven may recognize this convention, because it's borrowed from their ecosystem.

#### Testing sources

Besides these main sources, many projects contain other kinds of source files.
The most prominent ones are the *test source files*, which contain code to test your software but will never enter production.
Typical examples include unit tests written using a testing library like ScalaTest, ScalaCheck, or JUnit.
Of course, there can also be test resources, files that won't be compiled but are needed at the time of test execution as is.

To delineate the different dimensions of sources, sbt places the *compile source file* settings into a configuration called `Compile` and the *test source file* settings into a configuration called `Test`.
You can inspect the dependency tree for test sources by running the `inspect tree test:sources` command in the sbt shell:
```sbt
inspect tree test:sources
```
You may notice that the `test:sources` task uses the exact same lookup as the `compile:sources` task.
That's because under the covers, sbt is using the same set of settings to find your source files.
sbt does this same thing with the resources task, creating settings for configuring testing resources under the `test:resources` task.

#### Custom organization of sources

The lowest setting in the tree, `sourceDirectory`, which has type `File` in the Global configuration scope (`*`), is defined to be `src/`.
By default it depends on another setting of type `File: baseDirectory`, which points to the base directory of your project.
`sourceDirectory` points to a new `src` child directory underneath the project's `baseDirectory`.

Conceptually, this is sbt's default `sourceDirectory` configuration:
```sbt
sourceDirectory := new File(baseDirectory.value, "src")
```

#### Filtering the source you want

But sometimes you also want to have source code generated.
sbt supports that through so-called managed sources.
For now all you need to understand is that sources are distinguished into unmanaged - those you write - and managed - those that are generated.

For the unmanaged sources, sbt further applies filters to include and exclude source files.
You've already seen the default directories where you put your Scala and Java sources.
Using the filters, sbt determines which files from these directories should be treated as sources and which ones should be ignored.
By default the `include-filter` setting is initialized with a filter that includes all *.scala and *.java files, and the `exclude-filter` setting excludes any hidden files - for example, those starting with a dot (.).

Exclude filters take precedence over include filters.
The actual implementation runs the include filter first and then checks the exclude filter, leading to any excludes overriding the includes.

### Depending on libraries

It's practically impossible these days to work on a project without relying on libraries or other projects.
sbt provides a pretty robust way to specify dependencies, so figure 4.5 digs into it using the `inspect tree compile:dependencyClasspath`.

The dependencies are split into two parts:
* **Internal dependencies** - These are the dependencies between projects defined in the current sbt build.
* **External dependencies** - These are dependencies that must be pulled from somewhere outside, via Ivy or the filesystem.

Whereas internal dependencies are calculated using the project `dependsOn` method, external dependencies are a bit more involved.
They're further split into the following two components:
* **Unmanaged dependencies** - These are external dependencies sbt discovers from default locations.
* **Managed dependencies** - These are external dependencies you specify in the sbt build.
These dependencies are resolved by the `update` task.

#### Unmanaged dependencies

To add a library as an unmanaged dependency, drop a jar archive into the lib/ directory of your project.

sbt will put all libraries found in the lib/ directory on the project's `unmanagedClasspath`.
The default directory where sbt looks for libraries is also configurable.
You can do this by altering `unmanagedBase` of type File, but again, be aware that most sbt users will expect it to be named `lib/`.

#### Managed dependencies

The recommended approach to library dependencies is using managed dependencies.
If you've been using Maven, Gradle, or some other advanced build tool, the concept of declarative library management won't be new.
sbt's managed dependencies are similar: you declare one or more library dependencies in the build definition, and sbt will download these from a repository and put these on the classpath when needed.

Although `managedDependencies` can be used to specify files/jars directly, it's recommended to directly use Ivy and the `update` task.

The `update` task makes use of the configuration of Ivy for sbt and the configuration of the current project, called a *module* in Ivy.
The `ivySbt` task pulls in all the global configuration of Ivy, like where to look for dependencies and what credentials to use.
The `ivyModule` task pulls together all the configuration for the current project, like what its identifier (name) is, what dependencies it has, and what artifacts it will produce.

The most important setting to know about `IvySbt` is the `resolvers` setting.
This is where you can specify how and where to find libraries.
Although Ivy supports configurable lookup mechanisms, most projects make use of sbt's default, which is to load from a Maven repository.

Now that you have a location from where you'll pull artifacts, you can start configuring what artifacts to pull.

The `libraryDependencies` setting is defined as a collection of `ModuleID` values.
`ModuleID` is an sbt abstraction to simplify the declaration of dependencies.

`ModuleID` consists of three mandatory values: `organization`, `name`, and `revision`.
These are Ivy's variants of Maven's `groupId`, `artifactId`, and `version` attributes and are a way to uniquely identify a library.

In sbt, you can define a module ID using the `%` method against strings.
Simply specify the organization, name, and revision separated by `%`.
```sbt
libraryDependencies ++= Seq(
  "org.slf4j" % "slf4j-api" % "1.7.2",
  "ch.qos.logback" % "logback-classic" % "1.0.7"
)
```
As you can see, you're using strings to define `organization`, `name`, and `revision` of the two library dependencies.
The individual strings are combined with the `%` operator, which is provided by sbt as an extension method to `String` and creates a `ModuleID` as a result.

When it comes to dependencies on Scala libraries, you need to pay special attention to binary compatibility.
You have to use a version of the library that was compiled against the same or at least a binary-compatible version of Scala, like the one we're using for our project.

sbt has established a de facto standard where the Scala version is encoded in the `name` of the library by name mangling.
Actually, it's not the full Scala version that's added to the `name` but only the Scala binary version, which by default consists of the major and minor version numbers; for example, `2.10`.

Although this works, it's not only cumbersome to write the names of library dependencies is this fashion, but also error-prone.

Therefore, sbt offers a convenient and safe way to declare dependencies on cross-compiled Scala libraries.
Instead of the `%` operator, you use the `%%` operator between the `organization` and `name` and omit adding the Scala binary version to the name:
```sbt
libraryDependencies ++= Seq(
  "com.typesafe" %% "scalalogging-slf4j" % "0.4.0",
  "ch.qos.logback" % "logback-classic" % "1.0.7"
)
```
This is as easy as before, and sbt will automatically create a `ModuleID`, which has a name mangled with the Scala binary version.

#### Managed dependencies and configurations

Now that you understand how to declare library dependencies, let's take a look at executing more fine-grained control and scoping these to configurations.
Configurations usually come with their own sources and classpath;
for example, the `Compile` configuration uses the main sources, and the `Test` configuration the test sources.

Therefore, ScalaTest and all its transient dependencies have to be on the classpath.
But because these library dependencies are needed only to compile the test sources, it would be a bad idea to define them globally.
Instead, you can add the proper configuration to a `ModuleID`:
```sbt
libraryDependencies ++= Seq(
  "org.scalatest" %% "scalatest" % "3.0.5" % "test"
)
```
You append the name of the `Test` configuration to the library dependency, using an additional `%` operator to define the configuration.
By default, all dependencies are put onto the default configuration, used for both running and compiling all code in your project.

### Packaging your project

But there's a transformation that must happen between raw output of the compiler and the web server before you can deploy your software.
This is known as *packaging*.

The default sbt build is oriented around *open source JVM libraries*.
This means that, by default, sbt will package your project as reusable jar files that can be published to Ivy or Maven repositories and consumed by others.
Publishing to Ivy or Maven requires a few things:
* A jar file containing the library to share
* A jar file containing the source code of the shared library
* A jar file containing the documentation (Scaladoc or Javadoc) of the shared library
* A configuration file (pom.xml or ivy.xml) that identifies the project and where it came from

If you look at the default package task, using the `inspect tree package` command, you'll find a tree like the one in figure 4.7.

The `package` task depends on the `packageBin` task, which generated the binary artifact (jar) for the project.
The contents of this file are defined by the `mappings` in `packageBin` task.
The `mappings` task has the type `Seq[(File, String)]`, a list of files and string names.
The files are the list of files to include in the resulting jar, and the names are the location within the jar to store the file.

Although creating the project's binary artifacts is convenient, let's look at how sbt creates the other artifacts in the base build: the documentation and the source.

#### Identifying your project

Every project in an sbt build should have a sensible name.
Because this name will be used for artifacts created while packaging your project—for example, for jar files—you should use an expressive and sensible name.
This can be defined via the name setting:
```sbt
name := "Scala Notes"
```
Obviously, name is of type `Setting[String]`.
For a multimodule build (that is, one with multiple projects) it's common practice to have a base name with a suffix for each particular project.

## Chapter 5. Testing

### Configuring specs2 with sbt

#### Reporting and forking tests

### JUnit and using custom code

In fact, sbt isn't even running the Java test.
Why?
As you've seen, sbt "knows" how to run certain test frameworks out of the box.
But how does it know this?
sbt defines a `test-interface`, which allows sbt (1) to find the list of classes to run as tests, and (2) to run those tests.
JUnit doesn't know about this interface.

> The `test-interface` of sbt
>
> sbt supports, by default, ScalaTest, ScalaCheck, and specs2.
> This is because all of those test frameworks include in their jars a class that implements the sbt `test-interface` classes.
> JUnit does not, because it's not a Scala testing framework; it's a Java one.

In order to run your JUnit tests, you need to define an sbt test-interface for JUnit.
Fortunately, someone has already done it for you, and all you need to do is add it to the dependencies for your project.
It's called junit-interface:
```sbt
libraryDependencies += "junit" % "junit" % "4.11" % "test"
libraryDependencies += "com.novocode" % "junit-interface" % "0.11" % "test"            
```

#### Report generation with JUnit

### ScalaCheck

ScalaCheck is a test framework that's designed for property-based testing.
The main difference between a more traditional unit-testing framework and a property-based framework is that with a traditional framework, you have to provide the data with which to test your classes.
With a property-based framework, it provides the data.
You tell it what sort of data you want, and then it generates a set of data and runs the tests.
You need to provide some code that asserts that a combination of data is correct.

### Integration testing

#### ScalaTest and Selenium

Another commonly used Scala testing framework is ScalaTest.
ScalaTest implements a number of different styles of testing, including specification-style testing like specs2, unit testing like JUnit, and even behavior-driven development style testing.
Which style you use depends on what you want to test and what stage of your project that you're at.

## Chapter 6. The IO and Process libraries

Normally, when you package using sbt, it will create a jar containing just your classes.
But you want to package the application into a runnable jar so that it can be deployed to another server for system testing and eventually production.
For this you'll use the built-in sbt IO library.
This way, you're testing what you'll eventually deploy.

### Packaging using processes

### Packaging using the `sbt.IO` library

But in sbt, you generally don't need to do this, because sbt has a lot of built-in methods available by default in the `sbt.IO` package, and these are designed to be OS independent.

### More mappings

### Task dependencies

How do you declare that one task depends on another?
This is simple: you can define the inputs to a task by simply referencing the value inside the task.

It's as simple as that.
When the `build.sbt` is being compiled, sbt will read these dependencies and construct a dependency tree to determine which task can be executed when.

### Logging using the sbt logger

Sometimes it's useful to know what's going on in a task, especially if the task fails.
sbt provides a standard logging framework, called `Streams`, to enable you to add output to trace the build.
Adding this to your tasks is easy: you use `streams.value.log`.
This is a reference to the streams task, which provides per task logging and I/O via a `Streams` instance.
Using this has a number of advantages over a simple `println`.

## Chapter 7. Accepting user input

## Chapter 8. Using plugins and external libraries

## Chapter 9. Debugging your build

## Chapter 10. Automating workflows with commands

## Chapter 11. Defining a plugin
